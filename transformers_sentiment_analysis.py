# -*- coding: utf-8 -*-
"""Transformers_Sentiment_Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lR2yBVzVBPx3h-_KbaDNHRGhYxpIcj0z
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
from tqdm import tqdm
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import numpy as np
from torch.utils.data import DataLoader, TensorDataset

# Load model and tokenizer
MODEL = "cardiffnlp/twitter-roberta-base-sentiment"
tokenizer = AutoTokenizer.from_pretrained(MODEL)
model = AutoModelForSequenceClassification.from_pretrained(MODEL)

# Sentiment labels
labels = ['negative', 'neutral', 'positive']

# Use GPU if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

def get_batch_sentiments(input_ids, attention_mask):
    # Inference
    with torch.no_grad():
        outputs = model(input_ids=input_ids, attention_mask=attention_mask)

    # Softmax to get probabilities
    scores = outputs[0].cpu().numpy()
    softmax_scores = np.exp(scores) / np.sum(np.exp(scores), axis=1, keepdims=True)

    # Get sentiments
    sentiments = [labels[np.argmax(score)] for score in softmax_scores]

    return sentiments, softmax_scores

# Load dataset
k_df_labeled = pd.read_csv("/content/drive/MyDrive/labeled_k_comments.csv")

# Prepare data for batch processing
comments = k_df_labeled['Comments'].astype(str).tolist()  # Ensuring the comments are strings

# Tokenize the entire dataset
inputs = tokenizer(comments, return_tensors="pt", padding=True, truncation=True, max_length=512)

# Create a DataLoader to batch the inputs
batch_size = 16  # Reduced batch size to fit into memory
dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'])
dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)

# Store results
all_sentiments = []
all_scores = []

# Process in batches
model.eval()
for i, batch in tqdm(enumerate(dataloader), total=len(dataloader)):
    input_ids, attention_mask = batch  # Get the input batch
    input_ids = input_ids.to(device)
    attention_mask = attention_mask.to(device)

    # Get sentiment for the batch
    sentiments, scores = get_batch_sentiments(input_ids, attention_mask)

    all_sentiments.extend(sentiments)
    all_scores.extend(scores)

    # Clear cache after each batch (if using GPU)
    torch.cuda.empty_cache()

# Add results to DataFrame
k_df_labeled['Sentiment_Result'] = all_sentiments
k_df_labeled['Sentiment_Scores'] = all_scores

# Optionally, save to a new CSV file
k_df_labeled.to_csv("/content/drive/MyDrive/kendrick_comment_data_with_sentiment.csv", index=False)

