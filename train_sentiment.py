# -*- coding: utf-8 -*-
"""train_sentiment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-LgOMhbiG_QA_vj9Ym3AQDuQS3_K1na_
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report
import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.manifold import TSNE

k_labeled_df = pd.read_csv('/content/drive/MyDrive/labeled_k_comments.csv')

k_unlabeled_df = pd.read_csv('/content/drive/MyDrive/kendrick_comment_data.csv')

b

#merged_df = []

len(k_unlabeled_df)

len(k_labeled_df)

k_unlabeled_df.head()

k_labeled_df = k_labeled_df.rename(columns={'Comments':'comment'})

#merged_df = k_labeled_df.merge(k_unlabeled_df, on='comment', how='right')

#len(k_labeled_df)

#len(merged_df)

column_order = ['video_id','comment_id', 'comment', 'like_count', 'reply_count', 'published_at', 'label', 'confidence score']

k_labeled_df = k_labeled_df.drop_duplicates(subset='comment', keep='first')

merged_df = k_labeled_df.merge(k_unlabeled_df, on='comment', how='right')

labeled_df = merged_df[merged_df['label'].notna()].copy()
labeled_df = labeled_df.drop_duplicates(subset='comment', keep='first')

unlabeled_df = merged_df[merged_df['label'].isna()].copy()

print("Labeled (matched with metadata):", len(labeled_df))
print("Unlabeled:", len(unlabeled_df))

merged_df = merged_df[column_order]

unlabeled_df = unlabeled_df[column_order]

labeled_df = labeled_df[column_order]

labeled_df.head()

unlabeled_df.to_csv('/content/drive/MyDrive/unlabeled_kendrick_comments.csv', index=False)

len(unlabeled_df)

"""#### Training data"""

label_encoder = LabelEncoder()

# Train the data
def train_data(df):
    label_encoder = LabelEncoder()
    df['encoded_label'] = label_encoder.fit_transform(df['label'])

    X_train = df['comment']
    y_train = df['encoded_label']

    pipeline = Pipeline([
        ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2))),
        ('clf', LogisticRegression(max_iter=1000, class_weight='balanced'))
    ])

    pipeline.fit(X_train, y_train)
    return pipeline, label_encoder

def predict_and_filter(df, pipeline, label_encoder):
    df = df.dropna(subset=['comment']).copy()
    unlabeled_comments = df['comment']
    pred_probs = pipeline.predict_proba(unlabeled_comments)

    max_confidence = pred_probs.max(axis=1)
    pred_labels = pred_probs.argmax(axis=1)

    df['predicted_label'] = label_encoder.inverse_transform(pred_labels)
    df['predicted_confidence'] = max_confidence

    return df

# Train the model
pipeline, label_encoder = train_data(labeled_df)

# Predict on unlabeled data
unlabeled_df = predict_and_filter(unlabeled_df, pipeline, label_encoder)

# Get low-confidence predictions
low_conf_df = unlabeled_df[unlabeled_df['predicted_confidence'] < 0.7].sort_values(by='predicted_confidence')

# Step 4: Export for manual labeling
low_conf_df[['comment', 'predicted_label', 'predicted_confidence']].head(200).to_csv(
    "/content/drive/MyDrive/k_to_label_batch.csv", index=False)

low_conf_df.head()

"""#### Round 2 Training"""

labeled_df = pd.read_csv('/content/drive/MyDrive/labeled_beyonce_comments.csv')
unlabeled_df = pd.read_csv('/content/drive/MyDrive/unlabeled_beyonce_comments.csv')

# 1. Load your newly labeled batch
labeled_batch = pd.read_csv("/content/drive/MyDrive/new_labeled_bbatch.csv")

# 2. Add it to labeled data
labeled_df = pd.concat([labeled_df, labeled_batch], ignore_index=True)

# 3. Remove those labeled rows from unlabeled data
unlabeled_df = unlabeled_df[~unlabeled_df['comment'].isin(labeled_batch['comment'])]

# 4. Encode labels (in case you added a new class)
labeled_df['encoded_label'] = label_encoder.fit_transform(labeled_df['label'])

pipeline = Pipeline([('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2))),
      ('clf', LogisticRegression(max_iter=1000, class_weight='balanced'))])

# 5. Retrain the model
pipeline.fit(labeled_df['comment'], labeled_df['encoded_label'])

# 6. Predict and select a new low-confidence batch
unlabeled_df = predict_and_filter(unlabeled_df)

print(f"Labeled samples: {len(labeled_df)}")
print(f"Unlabeled samples remaining: {len(unlabeled_df)}")

labeled_batch = pd.read_csv('/content/drive/MyDrive/round2_b_labeled_batch - round2_b_to_label_batch.csv')

labeled_df = pd.concat([labeled_df, labeled_batch], ignore_index=True)

unlabeled_df.head()

pipeline = Pipeline([('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2))),
      ('clf', LogisticRegression(max_iter=1000, class_weight='balanced'))])
pipeline.fit(labeled_df['comment'], labeled_df['label'])

unlabeled_df = unlabeled_df.dropna(subset=['comment']).copy()

preds = pipeline.predict(unlabeled_df['comment'])
probs = pipeline.predict_proba(unlabeled_df['comment'])
unlabeled_df['predicted_label'] = preds
unlabeled_df['confidence'] = probs.max(axis=1)

unlabeled_df['predicted_label'].value_counts().plot(kind='bar', title='Predicted Sentiment Distribution', xlabel='Sentiment', ylabel='Count', color='skyblue', edgecolor='black')
plt.grid(axis='y')
plt.show()

unlabeled_df['predicted_label'].value_counts().plot(
    kind='bar', title='Predicted Sentiment Distribution on Unlabeled Data',
    xlabel='Sentiment', ylabel='Number of Comments', color='skyblue', edgecolor='black'
)
plt.grid(axis='y')
plt.show()

import seaborn as sns

plt.figure(figsize=(10,6))
sns.boxplot(x='predicted_label', y='confidence', data=unlabeled_df)
plt.title('Confidence by Predicted Sentiment')
plt.xlabel('Predicted Sentiment')
plt.ylabel('Confidence Score')
plt.grid(True)
plt.show()

from sklearn.manifold import TSNE

# Get TF-IDF features
tfidf = pipeline.named_steps['tfidf']
X_features = tfidf.transform(unlabeled_df['comment'])

# Reduce to 2D with t-SNE
tsne = TSNE(n_components=2, random_state=42, perplexity=30)
X_embedded = tsne.fit_transform(X_features.toarray())

# Add to DataFrame for plotting
unlabeled_df['tsne_1'] = X_embedded[:,0]
unlabeled_df['tsne_2'] = X_embedded[:,1]

# Plot
plt.figure(figsize=(10, 6))
sns.scatterplot(data=unlabeled_df, x='tsne_1', y='tsne_2', hue='predicted_label', alpha=0.7, palette='Set2')
plt.title('t-SNE Visualization of Predicted Sentiments')
plt.xlabel('Dimension 1')
plt.ylabel('Dimension 2')
plt.legend(title='Predicted Sentiment')
plt.grid(True)
plt.show()



# Get predicted probabilities and labels
probs = pipeline.predict_proba(unlabeled_df['comment'])
preds = pipeline.predict(unlabeled_df['comment'])

# Attach predictions to the unlabeled_df
unlabeled_df['predicted_label_encoded'] = preds
unlabeled_df['confidence'] = probs.max(axis=1)

# Decode predicted labels if needed
unlabeled_df['predicted_label'] = label_encoder.inverse_transform(unlabeled_df['predicted_label_encoded'])



labeled_df.to_csv('/content/drive/MyDrive/round2_labeled_b_comments')

low_conf_df_2 = unlabeled_df[unlabeled_df['predicted_confidence'] < 0.7].sort_values(by='predicted_confidence')
low_conf_df_2[['comment', 'predicted_label', 'predicted_confidence']].head(200).to_csv(
    "/content/drive/MyDrive/round2_b_to_label_batch.csv", index=False
)

